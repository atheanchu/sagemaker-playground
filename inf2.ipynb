{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae23f09",
   "metadata": {},
   "source": [
    "# Create your own chatbot with llama-2-13B on AWS Inferentia\n",
    "\n",
    "This guide will detail how to export, deploy and run a **LLama-2 13B** chat model on AWS inferentia.\n",
    "\n",
    "You will learn how to:\n",
    "- set up your AWS instance,\n",
    "- export the Llama-2 model to the Neuron format,\n",
    "- push the exported model to the Hugging Face Hub,\n",
    "- deploy the model and use it in a chat application.\n",
    "\n",
    "Note: This tutorial was created on a inf2.48xlarge AWS EC2 Instance.\n",
    "\n",
    "## Prerequisite: Setup AWS environment\n",
    "\n",
    "*you can skip that section if you are already running this notebook on your instance.*\n",
    "\n",
    "In this example, we will use the *inf2.48xlarge* instance with 12 Neuron devices, corresponding to 24 Neuron Cores and the [Hugging Face Neuron Deep Learning AMI](https://aws.amazon.com/marketplace/pp/prodview-gr3e6yiscria2).\n",
    "\n",
    "This guide doesnâ€™t cover how to create the instance in detail. You can refer to the [offical documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html). At step 4. you will select the\n",
    "[Hugging Face Neuron Deep Learning AMI](https://aws.amazon.com/marketplace/pp/prodview-gr3e6yiscria2) and at step 5. you will select an *inf2* instance type.\n",
    "\n",
    "Once the instance is up and running, you can ssh into it. But instead of developing inside a terminal you need to launch a Jupyter server to run this notebook.\n",
    "\n",
    "For this, you need first to add a port for forwarding in the ssh command, which will tunnel our localhost traffic to the AWS instance.\n",
    "\n",
    "From a local terminal, type the following commands:\n",
    "\n",
    "```shell\n",
    "HOSTNAME=\"\" # IP address, e.g. ec2-3-80-....\n",
    "KEY_PATH=\"\" # local path to key, e.g. ssh/trn.pem\n",
    "\n",
    "ssh -L 8080:localhost:8080 -i ${KEY_NAME}.pem ubuntu@$HOSTNAME\n",
    "```\n",
    "\n",
    "On the instance, you can now start the jupyter server.\n",
    "\n",
    "```\n",
    "python -m notebook --allow-root --port=8080\n",
    "```\n",
    "\n",
    "You should see a familiar jupyter output with a URL.\n",
    "\n",
    "You can click on it, and a jupyter environment will open in your local browser.\n",
    "\n",
    "You can then browse to this notebook (`notebooks/text-generation/llama2-13-chatbot`) to continue with the guide.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44142062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: ipywidgets in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipywidgets) (8.12.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipywidgets) (5.14.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: backcall in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/aws_neuron_venv_pytorch/lib/python3.8/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Special widgets are required for a nicer display\n",
    "import sys\n",
    "!{sys.executable} -m pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76e858",
   "metadata": {},
   "source": [
    "## 1. Export the Llama 2 model to Neuron\n",
    "\n",
    "For this guide, we will use the non-gated [NousResearch/Llama-2-13b-chat-hf](https://huggingface.co/NousResearch/Llama-2-13b-chat-hf) model, which is functionally equivalent to the original [meta-llama/Llama-2-13b-chat-hf](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf).\n",
    "\n",
    "This model is part of the **Llama 2** family of models, and has been tuned to recognize chat interactions\n",
    "between a *user* and an *assistant* (more on that later).\n",
    "\n",
    "As explained in the [optimum-neuron documentation](https://huggingface.co/docs/optimum-neuron/guides/export_model#why-compile-to-neuron-model)\n",
    ", models need to be compiled and exported to a serialized format before running them on Neuron devices.\n",
    "\n",
    "Fortunately, ðŸ¤— **optimum-neuron** offers a [very simple API](https://huggingface.co/docs/optimum-neuron/guides/models#configuring-the-export-of-a-generative-model)\n",
    "to export standard ðŸ¤— [transformers models](https://huggingface.co/docs/transformers/index) to the Neuron format.\n",
    "\n",
    "When exporting the model, we will specify two sets of parameters:\n",
    "\n",
    "- using *compiler_args*, we specify on how many cores we want the model to be deployed (each neuron device has two cores), and with which precision (here *float16*),\n",
    "- using *input_shapes*, we set the static input and output dimensions of the model. All model compilers require static shapes, and neuron makes no exception. Note that the\n",
    "*sequence_length* not only constrains the length of the input context, but also the length of the Key/Value cache, and thus, the output length.\n",
    "\n",
    "Depending on your choice of parameters and inferentia host, this may take from a few minutes to more than an hour.\n",
    "\n",
    "For your convenience, we host a pre-compiled version of that model on the Hugging Face hub, so you can skip the export and start using the model immediately in section 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612e39ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-02 05:08:00.000242:  9292  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neuronxcc-2.13.66.0+6dfecc895/MODULE_7ec41fbc85504de0b4d5 not found in aws-neuron/optimum-neuron-cache: 404 Client Error. (Request ID: Root=1-66331fb0-382a5c505472e8fe3990b034;9192fbbb-4b24-4666-ab7c-63677523be50)\n",
      "\n",
      "Entry Not Found for url: https://huggingface.co/api/models/aws-neuron/optimum-neuron-cache/tree/main/neuronxcc-2.13.66.0%2B6dfecc895%2FMODULE_7ec41fbc85504de0b4d5?recursive=True&expand=False.\n",
      "neuronxcc-2.13.66.0+6dfecc895/MODULE_7ec41fbc85504de0b4d5 does not exist on \"main\" \n",
      "The model will be recompiled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Compiling bge-m3 *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-02T05:08:18Z Running DoNothing\n",
      "2024-05-02T05:08:18Z DoNothing finished after 0.000 seconds\n",
      "2024-05-02T05:08:18Z Running AliasDependencyInduction\n",
      "2024-05-02T05:08:18Z AliasDependencyInduction finished after 0.006 seconds\n",
      "2024-05-02T05:08:18Z Running CanonicalizeIR\n",
      "2024-05-02T05:08:18Z CanonicalizeIR finished after 0.021 seconds\n",
      "2024-05-02T05:08:18Z Running LegalizeCCOpLayout\n",
      "2024-05-02T05:08:18Z LegalizeCCOpLayout finished after 0.022 seconds\n",
      "2024-05-02T05:08:18Z Running ResolveComplicatePredicates\n",
      "2024-05-02T05:08:18Z ResolveComplicatePredicates finished after 0.020 seconds\n",
      "2024-05-02T05:08:18Z Running AffinePredicateResolution\n",
      "2024-05-02T05:08:18Z AffinePredicateResolution finished after 0.021 seconds\n",
      "2024-05-02T05:08:18Z Running EliminateDivs\n",
      "2024-05-02T05:08:18Z EliminateDivs finished after 0.019 seconds\n",
      "2024-05-02T05:08:18Z Running PerfectLoopNest\n",
      "2024-05-02T05:08:18Z PerfectLoopNest finished after 0.020 seconds\n",
      "2024-05-02T05:08:18Z Running Simplifier\n",
      "2024-05-02T05:08:18Z Simplifier finished after 0.100 seconds\n",
      "2024-05-02T05:08:18Z Running GenericAccessSimplifier\n",
      "2024-05-02T05:08:18Z GenericAccessSimplifier finished after 0.019 seconds\n",
      "2024-05-02T05:08:18Z Running TCTransform\n",
      "2024-05-02T05:08:18Z TCTransform finished after 0.019 seconds\n",
      "2024-05-02T05:08:18Z Running CommuteConcat\n",
      "2024-05-02T05:08:18Z CommuteConcat finished after 0.020 seconds\n",
      "2024-05-02T05:08:18Z Running LowerTensorOp\n",
      "2024-05-02T05:08:19Z LowerTensorOp finished after 0.290 seconds\n",
      "2024-05-02T05:08:19Z Running ExpandBatchNorm\n",
      "2024-05-02T05:08:19Z ExpandBatchNorm finished after 0.058 seconds\n",
      "2024-05-02T05:08:19Z Running TCTransform\n",
      "2024-05-02T05:08:19Z TCTransform finished after 0.081 seconds\n",
      "2024-05-02T05:08:19Z Running EliminateDivs\n",
      "2024-05-02T05:08:19Z EliminateDivs finished after 0.046 seconds\n",
      "2024-05-02T05:08:19Z Running GenericAccessSimplifier\n",
      "2024-05-02T05:08:19Z GenericAccessSimplifier finished after 0.049 seconds\n",
      "2024-05-02T05:08:19Z Running CanonicalizeIR\n",
      "2024-05-02T05:08:19Z CanonicalizeIR finished after 0.046 seconds\n",
      "2024-05-02T05:08:19Z Running TensorOpFusion\n",
      "2024-05-02T05:08:19Z TensorOpFusion finished after 0.069 seconds\n",
      "2024-05-02T05:08:19Z Running TensorOpTransform\n",
      "2024-05-02T05:08:19Z TensorOpTransform finished after 0.209 seconds\n",
      "2024-05-02T05:08:19Z Running LateLowerTensorOp\n",
      "2024-05-02T05:08:19Z LateLowerTensorOp finished after 0.074 seconds\n",
      "2024-05-02T05:08:19Z Running MemcpyElimination\n",
      "2024-05-02T05:08:23Z MemcpyElimination finished after 3.514 seconds\n",
      "2024-05-02T05:08:23Z Running LoopFusion\n",
      "2024-05-02T05:08:24Z LoopFusion finished after 1.034 seconds\n",
      "2024-05-02T05:08:24Z Running Simplifier\n",
      "2024-05-02T05:08:24Z Simplifier finished after 0.187 seconds\n",
      "2024-05-02T05:08:24Z Running Delinearization\n",
      "2024-05-02T05:08:24Z Delinearization finished after 0.155 seconds\n",
      "2024-05-02T05:08:24Z Running AliasDependencyElimination\n",
      "2024-05-02T05:08:24Z AliasDependencyElimination finished after 0.025 seconds\n",
      "2024-05-02T05:08:24Z Running DeadStoreElimination\n",
      "2024-05-02T05:08:27Z DeadStoreElimination finished after 2.158 seconds\n",
      "2024-05-02T05:08:27Z Running AliasDependencyInduction\n",
      "2024-05-02T05:08:27Z AliasDependencyInduction finished after 0.007 seconds\n",
      "2024-05-02T05:08:27Z Running Simplifier\n",
      "2024-05-02T05:08:27Z Simplifier finished after 0.063 seconds\n",
      "2024-05-02T05:08:27Z Running LICM\n",
      "2024-05-02T05:08:27Z LICM finished after 0.053 seconds\n",
      "2024-05-02T05:08:27Z Running Delinearization\n",
      "2024-05-02T05:08:27Z Delinearization finished after 0.048 seconds\n",
      "2024-05-02T05:08:27Z Running LoopFusion\n",
      "2024-05-02T05:08:27Z LoopFusion finished after 0.337 seconds\n",
      "2024-05-02T05:08:27Z Running SimplifySlice\n",
      "2024-05-02T05:08:27Z SimplifySlice finished after 0.023 seconds\n",
      "2024-05-02T05:08:27Z Running LICM\n",
      "2024-05-02T05:08:27Z LICM finished after 0.048 seconds\n",
      "2024-05-02T05:08:27Z Running Simplifier\n",
      "2024-05-02T05:08:27Z Simplifier finished after 0.123 seconds\n",
      "2024-05-02T05:08:27Z Running ValueNumbering\n",
      "2024-05-02T05:08:27Z ValueNumbering finished after 0.056 seconds\n",
      "2024-05-02T05:08:27Z Running LICM\n",
      "2024-05-02T05:08:27Z LICM finished after 0.040 seconds\n",
      "2024-05-02T05:08:27Z Running PadElimination\n",
      "2024-05-02T05:08:27Z PadElimination finished after 0.002 seconds\n",
      "2024-05-02T05:08:27Z Running Delinearization\n",
      "2024-05-02T05:08:27Z Delinearization finished after 0.047 seconds\n",
      "2024-05-02T05:08:27Z Running LoopFusion\n",
      "2024-05-02T05:08:28Z LoopFusion finished after 0.246 seconds\n",
      "2024-05-02T05:08:28Z Running GenericAccessSimplifier\n",
      "2024-05-02T05:08:28Z GenericAccessSimplifier finished after 0.024 seconds\n",
      "2024-05-02T05:08:28Z Running Simplifier\n",
      "2024-05-02T05:08:28Z Simplifier finished after 0.061 seconds\n",
      "2024-05-02T05:08:28Z Running LICM\n",
      "2024-05-02T05:08:28Z LICM finished after 0.048 seconds\n",
      "2024-05-02T05:08:28Z Running ValueNumbering\n",
      "2024-05-02T05:08:28Z ValueNumbering finished after 0.047 seconds\n",
      "2024-05-02T05:08:28Z Running TCTransform\n",
      "2024-05-02T05:08:28Z TCTransform finished after 0.029 seconds\n",
      "2024-05-02T05:08:28Z Running CommuteConcat\n",
      "2024-05-02T05:08:28Z CommuteConcat finished after 0.025 seconds\n",
      "2024-05-02T05:08:28Z Running RecognizeOpIdiom\n",
      "2024-05-02T05:08:28Z RecognizeOpIdiom finished after 0.103 seconds\n",
      "2024-05-02T05:08:28Z Running MaskPropagation\n",
      "2024-05-02T05:08:28Z MaskPropagation finished after 0.056 seconds\n",
      "2024-05-02T05:08:28Z Running Recompute\n",
      "2024-05-02T05:08:28Z Recompute finished after 0.003 seconds\n",
      "2024-05-02T05:08:28Z Running DeadCodeElimination\n",
      "2024-05-02T05:08:28Z DeadCodeElimination finished after 0.026 seconds\n",
      "2024-05-02T05:08:28Z Running DoNothing\n",
      "2024-05-02T05:08:28Z DoNothing finished after 0.000 seconds\n",
      "2024-05-02T05:08:28Z Running MutateDataType\n",
      "2024-05-02T05:08:28Z MutateDataType finished after 0.020 seconds\n",
      "2024-05-02T05:08:28Z Running AutoCastTCInputs\n",
      "2024-05-02T05:08:28Z AutoCastTCInputs finished after 0.034 seconds\n",
      "2024-05-02T05:08:28Z Running GenericAccessSimplifier\n",
      "2024-05-02T05:08:28Z GenericAccessSimplifier finished after 0.024 seconds\n",
      "2024-05-02T05:08:28Z Running Simplifier\n",
      "2024-05-02T05:08:28Z Simplifier finished after 0.062 seconds\n",
      "2024-05-02T05:08:28Z Running AliasDependencyElimination\n",
      "2024-05-02T05:08:28Z AliasDependencyElimination finished after 0.025 seconds\n",
      "2024-05-02T05:08:28Z Running DelinearIndices\n",
      "2024-05-02T05:08:28Z DelinearIndices finished after 0.111 seconds\n",
      "2024-05-02T05:08:28Z Running Delinearization\n",
      "2024-05-02T05:08:29Z Delinearization finished after 0.046 seconds\n",
      "2024-05-02T05:08:29Z Running DelinearIndices\n",
      "2024-05-02T05:08:29Z DelinearIndices finished after 0.106 seconds\n",
      "2024-05-02T05:08:29Z Running DeadCodeElimination\n",
      "2024-05-02T05:08:29Z DeadCodeElimination finished after 0.026 seconds\n",
      "2024-05-02T05:08:29Z Running InferIntrinsicOnCC\n",
      "2024-05-02T05:08:29Z InferIntrinsicOnCC finished after 0.324 seconds\n",
      "2024-05-02T05:08:29Z Running ResolveAccessConflict\n",
      "2024-05-02T05:08:29Z ResolveAccessConflict finished after 0.153 seconds\n",
      "2024-05-02T05:08:29Z Running LICM\n",
      "2024-05-02T05:08:29Z LICM finished after 0.050 seconds\n",
      "2024-05-02T05:08:29Z Running LocalLayoutOpt\n",
      "2024-05-02T05:08:30Z LocalLayoutOpt finished after 0.308 seconds\n",
      "2024-05-02T05:08:30Z Running DelinearIndices\n",
      "2024-05-02T05:08:30Z DelinearIndices finished after 0.118 seconds\n",
      "2024-05-02T05:08:30Z Running OrigLayoutTilingPipeline\n",
      "2024-05-02T05:08:30Z Running GlobalLayoutOpt\n",
      "2024-05-02T05:08:32Z GlobalLayoutOpt finished after 2.801 seconds\n",
      "2024-05-02T05:08:32Z Running CanonicalizeDAG\n",
      "2024-05-02T05:08:33Z CanonicalizeDAG finished after 0.053 seconds\n",
      "2024-05-02T05:08:33Z Running FlattenAxesForTiling\n",
      "2024-05-02T05:08:33Z FlattenAxesForTiling finished after 0.054 seconds\n",
      "2024-05-02T05:08:33Z Running SundaSizeTiling\n",
      "2024-05-02T05:08:38Z SundaSizeTiling finished after 5.628 seconds\n",
      "2024-05-02T05:08:38Z OrigLayoutTilingPipeline finished after 8.557 seconds\n",
      "2024-05-02T05:08:38Z Running TilingProfiler\n",
      "2024-05-02T05:08:39Z TilingProfiler finished after 0.285 seconds\n",
      "2024-05-02T05:08:39Z Running FlattenMacroLoop\n",
      "2024-05-02T05:08:39Z FlattenMacroLoop finished after 0.212 seconds\n",
      "2024-05-02T05:08:39Z Running InferNeuronTensor\n",
      "2024-05-02T05:08:40Z InferNeuronTensor finished after 1.485 seconds\n",
      "2024-05-02T05:08:40Z Running NeuronSimplifier\n",
      "2024-05-02T05:08:41Z NeuronSimplifier finished after 0.319 seconds\n",
      "2024-05-02T05:08:41Z Running LICM\n",
      "2024-05-02T05:08:41Z LICM finished after 0.105 seconds\n",
      "2024-05-02T05:08:41Z Running RewriteReplicationMatmul\n",
      "2024-05-02T05:08:41Z RewriteReplicationMatmul finished after 0.063 seconds\n",
      "2024-05-02T05:08:41Z Running FlattenMacroLoop\n",
      "2024-05-02T05:08:41Z FlattenMacroLoop finished after 0.225 seconds\n",
      "2024-05-02T05:08:41Z Running SimplifyMacroPredicates\n",
      "2024-05-02T05:08:42Z SimplifyMacroPredicates finished after 0.599 seconds\n",
      "2024-05-02T05:08:42Z Running DataLocalityOpt\n",
      "2024-05-02T05:08:43Z DataLocalityOpt finished after 1.288 seconds\n",
      "2024-05-02T05:08:43Z Running DMATilingProfiler\n",
      "2024-05-02T05:08:43Z DMATilingProfiler finished after 0.064 seconds\n",
      "2024-05-02T05:08:43Z Running NeuronSimplifier\n",
      "2024-05-02T05:08:43Z NeuronSimplifier finished after 0.320 seconds\n",
      "2024-05-02T05:08:43Z Running LegalizeSundaMacro\n",
      "2024-05-02T05:08:43Z LegalizeSundaMacro finished after 0.127 seconds\n",
      "2024-05-02T05:08:43Z Running NeuronSimplifier\n",
      "2024-05-02T05:08:44Z NeuronSimplifier finished after 0.322 seconds\n",
      "2024-05-02T05:08:44Z Running PerfectLoopNest\n",
      "2024-05-02T05:08:44Z PerfectLoopNest finished after 0.060 seconds\n",
      "2024-05-02T05:08:44Z Running FlattenMacroLoop\n",
      "2024-05-02T05:08:44Z FlattenMacroLoop finished after 0.075 seconds\n",
      "2024-05-02T05:08:44Z Running RewriteWeights\n",
      "2024-05-02T05:08:44Z RewriteWeights finished after 0.050 seconds\n",
      "2024-05-02T05:08:44Z Running ReshapeWeights\n",
      "2024-05-02T05:08:44Z ReshapeWeights finished after 0.013 seconds\n",
      "2024-05-02T05:08:44Z Running FlattenMacroLoop\n",
      "2024-05-02T05:08:44Z FlattenMacroLoop finished after 0.077 seconds\n",
      "2024-05-02T05:08:44Z Running SimplifyMacroPredicates\n",
      "2024-05-02T05:08:45Z SimplifyMacroPredicates finished after 0.664 seconds\n",
      "2024-05-02T05:08:45Z Running InferInitValue\n",
      "2024-05-02T05:08:49Z InferInitValue finished after 3.701 seconds\n",
      "2024-05-02T05:08:49Z Running NeuronSimplifier\n",
      "2024-05-02T05:08:49Z NeuronSimplifier finished after 0.315 seconds\n",
      "2024-05-02T05:08:49Z Running SimplifyTensor\n",
      "2024-05-02T05:08:50Z SimplifyTensor finished after 0.175 seconds\n",
      "2024-05-02T05:08:50Z Running LICM\n",
      "2024-05-02T05:08:50Z LICM finished after 0.094 seconds\n",
      "2024-05-02T05:08:50Z Running SundaISel\n",
      "2024-05-02T05:08:52Z SundaISel finished after 1.644 seconds\n",
      "2024-05-02T05:08:52Z Running PreprocessNkiKernels\n",
      "2024-05-02T05:08:52Z PreprocessNkiKernels finished after 0.039 seconds\n",
      "2024-05-02T05:08:52Z Running NeuronLoopInterchange\n",
      "2024-05-02T05:08:52Z NeuronLoopInterchange finished after 0.053 seconds\n",
      "2024-05-02T05:08:52Z Running NeuronSimplifyPredicates\n",
      "2024-05-02T05:08:52Z NeuronSimplifyPredicates finished after 0.039 seconds\n",
      "2024-05-02T05:08:52Z Running NeuronLoopFusion\n",
      "2024-05-02T05:08:53Z NeuronLoopFusion finished after 0.760 seconds\n",
      "2024-05-02T05:08:53Z Running NeuronLoopInterchange\n",
      "2024-05-02T05:08:53Z NeuronLoopInterchange finished after 0.036 seconds\n",
      "2024-05-02T05:08:53Z Running NeuronLICM\n",
      "2024-05-02T05:08:54Z NeuronLICM finished after 0.216 seconds\n",
      "2024-05-02T05:08:54Z Running FactorizeBlkDims\n",
      "2024-05-02T05:08:55Z FactorizeBlkDims finished after 0.557 seconds\n",
      "2024-05-02T05:08:55Z Running NeuronInstComb\n",
      "2024-05-02T05:08:56Z NeuronInstComb finished after 0.993 seconds\n",
      "2024-05-02T05:08:56Z Running NeuronValueNumbering\n",
      "2024-05-02T05:08:56Z NeuronValueNumbering finished after 0.176 seconds\n",
      "2024-05-02T05:08:56Z Running NeuronInstComb\n",
      "2024-05-02T05:08:57Z NeuronInstComb finished after 0.364 seconds\n",
      "2024-05-02T05:08:57Z Running VectorizeDMA\n",
      "2024-05-02T05:08:57Z VectorizeDMA finished after 0.244 seconds\n",
      "2024-05-02T05:08:57Z Running NeuronSimplifyPredicates\n",
      "2024-05-02T05:08:58Z NeuronSimplifyPredicates finished after 0.036 seconds\n",
      "2024-05-02T05:08:58Z Running LegalizePartitionReduce\n",
      "2024-05-02T05:08:58Z LegalizePartitionReduce finished after 0.090 seconds\n",
      "2024-05-02T05:08:58Z Running DeConcat\n",
      "2024-05-02T05:08:58Z DeConcat finished after 0.025 seconds\n",
      "2024-05-02T05:08:58Z Running PartialSimdFusion\n",
      "2024-05-02T05:08:59Z PartialSimdFusion finished after 1.357 seconds\n",
      "2024-05-02T05:09:00Z Running TritiumFusion\n",
      "2024-05-02T05:09:02Z TritiumFusion finished after 2.314 seconds\n",
      "2024-05-02T05:09:02Z Running CCOpFusion\n",
      "2024-05-02T05:09:02Z CCOpFusion finished after 0.516 seconds\n",
      "2024-05-02T05:09:02Z Running VectorizeMatMult\n",
      "2024-05-02T05:09:03Z VectorizeMatMult finished after 0.387 seconds\n",
      "2024-05-02T05:09:03Z Running PartialLoopFusion\n",
      "2024-05-02T05:09:03Z PartialLoopFusion finished after 0.484 seconds\n",
      "2024-05-02T05:09:03Z Running NeuronLICM\n",
      "2024-05-02T05:09:03Z NeuronLICM finished after 0.128 seconds\n",
      "2024-05-02T05:09:03Z Running LowerTranspose\n",
      "2024-05-02T05:09:04Z LowerTranspose finished after 0.835 seconds\n",
      "2024-05-02T05:09:04Z Running LateNeuronInstComb\n",
      "2024-05-02T05:09:06Z LateNeuronInstComb finished after 1.779 seconds\n",
      "2024-05-02T05:09:06Z Running SplitAccGrp\n",
      "2024-05-02T05:09:06Z SplitAccGrp finished after 0.041 seconds\n",
      "2024-05-02T05:09:06Z Running SpillPSum\n",
      "2024-05-02T05:09:07Z SpillPSum finished after 0.697 seconds\n",
      "2024-05-02T05:09:07Z Running LowerIntrinsics\n",
      "2024-05-02T05:09:07Z LowerIntrinsics finished after 0.043 seconds\n",
      "2024-05-02T05:09:07Z Running LegalizeType\n",
      "2024-05-02T05:09:07Z LegalizeType finished after 0.101 seconds\n",
      "2024-05-02T05:09:07Z Running NeuronLICM\n",
      "2024-05-02T05:09:07Z NeuronLICM finished after 0.155 seconds\n",
      "2024-05-02T05:09:07Z Running InferPSumTensor\n",
      "2024-05-02T05:09:08Z InferPSumTensor finished after 1.038 seconds\n",
      "2024-05-02T05:09:08Z Running WeightCoalescing\n",
      "2024-05-02T05:09:08Z WeightCoalescing finished after 0.042 seconds\n",
      "2024-05-02T05:09:08Z Running LegalizeSundaAccess\n",
      "2024-05-02T05:09:08Z LegalizeSundaAccess finished after 0.343 seconds\n",
      "2024-05-02T05:09:08Z Running RelaxPredicates\n",
      "2024-05-02T05:09:09Z RelaxPredicates finished after 0.067 seconds\n",
      "2024-05-02T05:09:09Z Running TensorInitialization\n",
      "2024-05-02T05:09:09Z TensorInitialization finished after 0.038 seconds\n",
      "2024-05-02T05:09:09Z Running NeuronSimplifyPredicates\n",
      "2024-05-02T05:09:09Z NeuronSimplifyPredicates finished after 0.041 seconds\n",
      "2024-05-02T05:09:09Z Running ExpandISAMacro\n",
      "2024-05-02T05:09:09Z ExpandISAMacro finished after 0.062 seconds\n",
      "2024-05-02T05:09:09Z Running SimplifyNeuronTensor\n",
      "2024-05-02T05:09:09Z SimplifyNeuronTensor finished after 0.244 seconds\n",
      "2024-05-02T05:09:09Z Running DMALocalityOpt\n",
      "2024-05-02T05:09:09Z DMALocalityOpt finished after 0.023 seconds\n",
      "2024-05-02T05:09:09Z Running DataStreaming\n",
      "2024-05-02T05:09:09Z DataStreaming finished after 0.128 seconds\n",
      "2024-05-02T05:09:09Z Running SFKVectorizer\n",
      "2024-05-02T05:09:15Z SFKVectorizer finished after 6.078 seconds\n",
      "2024-05-02T05:09:15Z Running LateLegalizeInst\n",
      "2024-05-02T05:09:16Z LateLegalizeInst finished after 0.317 seconds\n",
      "2024-05-02T05:09:16Z Running CoalesceCCOp\n",
      "2024-05-02T05:09:16Z CoalesceCCOp finished after 0.057 seconds\n",
      "2024-05-02T05:09:16Z Running SimpleAllReduceTiling\n",
      "2024-05-02T05:09:16Z SimpleAllReduceTiling finished after 0.054 seconds\n",
      "2024-05-02T05:09:16Z Running StaticProfiler\n",
      "2024-05-02T05:09:16Z StaticProfiler finished after 0.147 seconds\n",
      "2024-05-02T05:09:16Z Running SplitAPUnionSets\n",
      "2024-05-02T05:09:17Z SplitAPUnionSets finished after 0.758 seconds\n",
      "2024-05-02T05:09:17Z Running DumpGraphAndMetadata\n",
      "2024-05-02T05:09:17Z DumpGraphAndMetadata finished after 0.160 seconds\n",
      "2024-05-02T05:09:17Z Running BirCodeGenLoop\n",
      "2024-05-02T05:09:20Z BirCodeGenLoop finished after 3.300 seconds\n",
      "2024-05-02T05:09:33Z Running mod_parallel_pass\n",
      "2024-05-02T05:09:33Z Running rewrite_matmult_sparse\n",
      "2024-05-02T05:09:33Z rewrite_matmult_sparse finished after 0.004 seconds\n",
      "2024-05-02T05:09:33Z Running birverifier\n",
      "2024-05-02T05:09:34Z birverifier finished after 0.286 seconds\n",
      "2024-05-02T05:09:34Z Running expand_replication\n",
      "2024-05-02T05:09:34Z expand_replication finished after 0.004 seconds\n",
      "2024-05-02T05:09:34Z Running unroll\n",
      "2024-05-02T05:09:35Z unroll finished after 1.275 seconds\n",
      "2024-05-02T05:09:35Z Running psum_legalization\n",
      "2024-05-02T05:09:35Z psum_legalization finished after 0.025 seconds\n",
      "2024-05-02T05:09:35Z Running error_injector\n",
      "2024-05-02T05:09:35Z error_injector finished after 0.003 seconds\n",
      "2024-05-02T05:09:35Z Running constant_propagate\n",
      "2024-05-02T05:09:35Z constant_propagate finished after 0.168 seconds\n",
      "2024-05-02T05:09:35Z Running vn_splitter\n",
      "2024-05-02T05:09:35Z vn_splitter finished after 0.181 seconds\n",
      "2024-05-02T05:09:35Z Running lower_ac\n",
      "2024-05-02T05:09:35Z lower_ac finished after 0.019 seconds\n",
      "2024-05-02T05:09:35Z Running input_dma_coalescing\n",
      "2024-05-02T05:09:36Z input_dma_coalescing finished after 0.055 seconds\n",
      "2024-05-02T05:09:36Z Running early_peephole_opts\n",
      "2024-05-02T05:09:36Z early_peephole_opts finished after 0.020 seconds\n",
      "2024-05-02T05:09:36Z Running pre_sched\n",
      "2024-05-02T05:09:37Z pre_sched finished after 0.971 seconds\n",
      "2024-05-02T05:09:37Z Running tensor_copy_elim\n",
      "2024-05-02T05:09:37Z tensor_copy_elim finished after 0.182 seconds\n",
      "2024-05-02T05:09:37Z Running mm_packing\n",
      "2024-05-02T05:09:38Z mm_packing finished after 0.878 seconds\n",
      "2024-05-02T05:09:38Z Running coloring_allocator_psum\n",
      "2024-05-02T05:09:38Z coloring_allocator_psum finished after 0.447 seconds\n",
      "2024-05-02T05:09:38Z Running dma_optimization_psum\n",
      "2024-05-02T05:09:38Z dma_optimization_psum finished after 0.125 seconds\n",
      "2024-05-02T05:09:38Z Running address_rotation_psum\n",
      "2024-05-02T05:09:39Z address_rotation_psum finished after 0.452 seconds\n",
      "2024-05-02T05:09:39Z Running coloring_allocator_sb\n",
      "2024-05-02T05:09:41Z coloring_allocator_sb finished after 2.254 seconds\n",
      "2024-05-02T05:09:41Z Running address_rotation_sb\n",
      "2024-05-02T05:09:41Z address_rotation_sb finished after 0.194 seconds\n",
      "2024-05-02T05:09:41Z Running dma_optimization_sb\n",
      "2024-05-02T05:09:43Z dma_optimization_sb finished after 2.321 seconds\n",
      "2024-05-02T05:09:43Z Running address_rotation_sb\n",
      "2024-05-02T05:09:57Z address_rotation_sb finished after 13.059 seconds\n",
      "2024-05-02T05:09:57Z Running coloring_allocator_dram\n",
      "2024-05-02T05:09:57Z coloring_allocator_dram finished after 0.319 seconds\n",
      "2024-05-02T05:09:57Z Running address_rotation_dram\n",
      "2024-05-02T05:09:57Z address_rotation_dram finished after 0.135 seconds\n",
      "2024-05-02T05:09:57Z Running tensorcopy_accel\n",
      "2024-05-02T05:09:57Z tensorcopy_accel finished after 0.017 seconds\n",
      "2024-05-02T05:09:57Z Running peephole_opts\n",
      "2024-05-02T05:09:57Z peephole_opts finished after 0.098 seconds\n",
      "2024-05-02T05:09:57Z Running lower_kernel\n",
      "2024-05-02T05:09:57Z lower_kernel finished after 0.016 seconds\n",
      "2024-05-02T05:09:57Z Running build_fdeps\n",
      "2024-05-02T05:09:58Z build_fdeps finished after 0.581 seconds\n",
      "2024-05-02T05:09:58Z Running remove_redundancies\n",
      "2024-05-02T05:09:58Z remove_redundancies finished after 0.071 seconds\n",
      "2024-05-02T05:09:58Z Running anti_dependency_analyzer\n",
      "2024-05-02T05:09:59Z anti_dependency_analyzer finished after 0.982 seconds\n",
      "2024-05-02T05:09:59Z Running tensor_copy_elim\n",
      "2024-05-02T05:09:59Z tensor_copy_elim finished after 0.199 seconds\n",
      "2024-05-02T05:09:59Z Running post_sched\n",
      "2024-05-02T05:10:03Z post_sched finished after 3.659 seconds\n",
      "2024-05-02T05:10:03Z Running address_rotation_sb\n",
      "2024-05-02T05:10:13Z address_rotation_sb finished after 10.485 seconds\n",
      "2024-05-02T05:10:13Z Running anti_dependency_analyzer\n",
      "2024-05-02T05:10:14Z anti_dependency_analyzer finished after 1.015 seconds\n",
      "2024-05-02T05:10:14Z Running dep_opt\n",
      "2024-05-02T05:10:15Z dep_opt finished after 0.788 seconds\n",
      "2024-05-02T05:10:15Z Running report_stats\n",
      "2024-05-02T05:10:15Z report_stats finished after 0.054 seconds\n",
      "2024-05-02T05:10:15Z Running assign_trigger_engine\n",
      "2024-05-02T05:10:15Z assign_trigger_engine finished after 0.071 seconds\n",
      "2024-05-02T05:10:15Z Running alloc_queues\n",
      "2024-05-02T05:10:15Z alloc_queues finished after 0.036 seconds\n",
      "2024-05-02T05:10:15Z mod_parallel_pass finished after 41.772 seconds\n",
      "2024-05-02T05:10:15Z Running dep_reduction\n",
      "2024-05-02T05:10:17Z dep_reduction finished after 1.638 seconds\n",
      "2024-05-02T05:10:17Z Running bir_racecheck\n",
      "2024-05-02T05:10:18Z bir_racecheck finished after 1.368 seconds\n",
      "2024-05-02T05:10:18Z Running lower_dma\n",
      "2024-05-02T05:10:19Z lower_dma finished after 0.330 seconds\n",
      "2024-05-02T05:10:19Z Running coalesce_dma_blocks\n",
      "2024-05-02T05:10:19Z coalesce_dma_blocks finished after 0.108 seconds\n",
      "2024-05-02T05:10:19Z Running alloc_semaphores\n",
      "2024-05-02T05:10:19Z alloc_semaphores finished after 0.180 seconds\n",
      "2024-05-02T05:10:19Z Running expand_inst_late\n",
      "2024-05-02T05:10:19Z expand_inst_late finished after 0.027 seconds\n",
      "2024-05-02T05:10:19Z Running lower_sync\n",
      "2024-05-02T05:10:19Z lower_sync finished after 0.113 seconds\n",
      "2024-05-02T05:10:19Z Running lower_act\n",
      "2024-05-02T05:10:19Z lower_act finished after 0.208 seconds\n",
      "2024-05-02T05:10:19Z Running lower_dve\n",
      "2024-05-02T05:10:19Z lower_dve finished after 0.178 seconds\n",
      "2024-05-02T05:10:20Z Running lower_ap\n",
      "2024-05-02T05:10:20Z lower_ap finished after 0.061 seconds\n",
      "2024-05-02T05:10:20Z Running alloc_regs\n",
      "2024-05-02T05:10:20Z alloc_regs finished after 0.007 seconds\n",
      "2024-05-02T05:10:20Z Running birverifier\n",
      "2024-05-02T05:10:20Z birverifier finished after 0.262 seconds\n",
      "2024-05-02T05:10:20Z Running codegen\n",
      "2024-05-02T05:10:21Z isa_gen finished after 1.098 seconds\n",
      "2024-05-02T05:10:21Z dma_desc_gen finished after 0.223 seconds\n",
      "2024-05-02T05:10:22Z debug_info_gen finished after 0.544 seconds\n",
      "2024-05-02T05:10:22Z codegen finished after 1.982 seconds\n",
      "2024-05-02T05:10:22Z Running neff_packager\n",
      "2024-05-02T05:10:22Z neff_packager finished after 0.346 seconds\n",
      "2024-05-02T05:10:23Z Compiler status PASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Compilation Time] 141.89 seconds.\n",
      "[Total compilation Time] 141.89 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-02 05:10:26.000737:  9292  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n",
      "2024-05-02 05:10:26.000740:  9292  INFO ||NEURON_CACHE||: Compile cache path: /var/tmp/neuron-compile-cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model cached in: /var/tmp/neuron-compile-cache/neuronxcc-2.13.66.0+6dfecc895/MODULE_24e2f560880289a86b4e.\n"
     ]
    }
   ],
   "source": [
    "from optimum.neuron import NeuronModelForSentenceTransformers\n",
    "\n",
    "# Sentence Transformers model from HuggingFace\n",
    "model_id = \"BAAI/bge-m3\"\n",
    "input_shapes = {\"batch_size\": 1, \"sequence_length\": 1024}  # mandatory shapes\n",
    "\n",
    "# Load Transformers model and export it to AWS Inferentia2\n",
    "model = NeuronModelForSentenceTransformers.from_pretrained(\n",
    "    model_id, export=True, cache_dir=\"/tmp/bge-m3-cache\", **input_shapes\n",
    ")\n",
    "\n",
    "# Save model to disk\n",
    "model.save_pretrained(\"bge_m3_inf2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25440470",
   "metadata": {},
   "source": [
    "This probably took a while.\n",
    "\n",
    "Fortunately, you will need to do this only once because you can save your model and reload it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ddcd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"bge_m3_inf2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221d9ad",
   "metadata": {},
   "source": [
    "Even better, you can push it to the [Hugging Face hub](https://huggingface.co/models).\n",
    "\n",
    "For that, you need to be logged in to a [HuggingFace account](https://huggingface.co/join).\n",
    "\n",
    "If you are not connected already on your instance, you will now be prompted for an access token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762a9e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User is already logged in.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login(new_session=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c4cc7",
   "metadata": {},
   "source": [
    "By default, the model will be uploaded to your account (organization equal to your user name).\n",
    "\n",
    "Feel free to edit the cell below if you want to upload the model to a specific [Hugging Face organization](https://huggingface.co/docs/hub/organizations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79155c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ad9da064654323ab27da068dab58cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.neuron:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a975984609974e54be48221ee1d9f833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59591800cd34f4c9bb353ef5bad677f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "\n",
    "org = whoami()[\"name\"]\n",
    "\n",
    "repo_id = f\"{org}/bge_m3_inf2\"\n",
    "\n",
    "model.push_to_hub(\"bge_m3_inf2\", repository_id=repo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96303dbe",
   "metadata": {},
   "source": [
    "### A few more words about export parameters.\n",
    "\n",
    "The minimum memory required to load a model can be computed with:\n",
    "\n",
    "```\n",
    "   memory = bytes per parameter * number of parameters\n",
    "```\n",
    "\n",
    "The **Llama 2 13B** model uses *float16* weights (stored on 2 bytes) and has 13 billion parameters, which means it requires at least 2 * 13B or ~26GB of memory to store its weights.\n",
    "\n",
    "Each NeuronCore has 16GB of memory which means that a 26GB model cannot fit on a single NeuronCore.\n",
    "\n",
    "In reality, the total space required is much greater than just the number of parameters due to caching attention layer projections (KV caching).\n",
    "This caching mechanism grows memory allocations linearly with sequence length and batch size.\n",
    "\n",
    "Here we set the *batch_size* to 1, meaning that we can only process one input prompt in parallel. We set the *sequence_length* to 2048, which corresponds to half the model maximum capacity (4096).\n",
    "\n",
    "The formula to evaluate the size of the KV cache is more involved as it also depends on parameters related to the model architecture, such as the width of the embeddings and the number of decoder blocks.\n",
    "\n",
    "Bottom-line is, to get very large language models to fit, tensor parallelism is used to split weights, data, and compute across multiple NeuronCores, keeping in mind that the memory on each core cannot exceed 16GB.\n",
    "\n",
    "Note that increasing the number of cores beyond the minimum requirement almost always results in a faster model.\n",
    "Increasing the tensor parallelism degree improves memory bandwidth which improves model performance.\n",
    "\n",
    "To optimize performance it's recommended to use all cores available on the instance.\n",
    "\n",
    "In this guide we use all the 24 cores of the *inf2.48xlarge*, but this should be changed to 12 if you are\n",
    "using a *inf2.24xlarge* instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d21867",
   "metadata": {},
   "source": [
    "## 2. Generate text using Llama 2 on AWS Inferentia2\n",
    "\n",
    "Once your model has been exported, you can generate text using the transformers library, as it has been described in [detail in this post](https://huggingface.co/blog/how-to-generate).\n",
    "\n",
    "If as suggested you skipped the first section, don't worry: we will use a precompiled model already present on the hub instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac1a7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.neuron import NeuronModelForCausalLM\n",
    "\n",
    "try:\n",
    "    model\n",
    "except NameError:\n",
    "    # Edit this to use another base model\n",
    "    model = NeuronModelForCausalLM.from_pretrained(\n",
    "        \"aws-neuron/BAAI/bge-m3-13b-chat-hf-neuron-latency\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a034c58",
   "metadata": {},
   "source": [
    "We will need a *Llama 2* tokenizer to convert the prompt strings to text tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832d93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_id = \"BAAI/bge-m3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a048db",
   "metadata": {},
   "source": [
    "The following generation strategies are supported:\n",
    "\n",
    "- greedy search,\n",
    "- multinomial sampling with top-k and top-p (with temperature).\n",
    "\n",
    "Most logits pre-processing/filters (such as repetition penalty) are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7947684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding input tensors, the padding side is: right.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token embeddings: torch.Size([1, 8, 1024])\n",
      "sentence_embedding: torch.Size([1, 1024])\n",
      "tensor([[[ 7.2326e-02,  5.7962e-01, -1.0161e+00,  ..., -9.5186e-02,\n",
      "          -8.3638e-01,  4.9044e-01],\n",
      "         [-2.9362e-02,  5.0794e-02, -4.4895e-01,  ...,  7.0900e-02,\n",
      "          -6.4030e-01,  4.0967e-01],\n",
      "         [ 7.3407e-01, -1.4117e-01, -5.7145e-01,  ...,  3.4220e-01,\n",
      "          -5.4862e-01,  7.3620e-01],\n",
      "         ...,\n",
      "         [ 1.0254e+00, -3.7437e-01, -2.2843e-01,  ...,  1.9539e-02,\n",
      "          -4.5130e-01, -5.5243e-02],\n",
      "         [ 2.2791e-01,  1.3206e-01, -9.9534e-02,  ..., -7.7430e-04,\n",
      "          -8.7546e-01,  5.6866e-01],\n",
      "         [-3.7476e-01,  3.4859e-01,  1.5830e-01,  ...,  6.5258e-01,\n",
      "          -5.3151e-01,  5.7769e-01]]])\n",
      "tensor([[ 0.0027,  0.0217, -0.0380,  ..., -0.0036, -0.0313,  0.0183]])\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "prompt = \"I like to eat apples\"\n",
    "encoded_input = tokenizer(prompt, return_tensors=\"pt\")\n",
    "outputs = model(**encoded_input)\n",
    "\n",
    "token_embeddings = outputs.token_embeddings\n",
    "sentence_embedding = outputs.sentence_embedding\n",
    "\n",
    "print(f\"token embeddings: {token_embeddings.shape}\")  # torch.Size([1, 7, 384])\n",
    "print(f\"sentence_embedding: {sentence_embedding.shape}\")  # torch.Size([1, 384])\n",
    "print(token_embeddings)\n",
    "print(sentence_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
