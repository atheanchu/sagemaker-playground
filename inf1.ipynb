{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip config set global.extra-index-url https://pip.repos.neuron.amazonaws.com\n",
    "!pip install torch-neuron neuron-cc[tensorflow] \"protobuf\" torchvision!pip install boto3\n",
    "!pip install transformers==4.34.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/yanolja/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch_neuron\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"BAAI/bge-m3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_0 = \"hello\"\n",
    "sequence_1 = \"hi\"\n",
    "\n",
    "tokenized_sequence_pair = tokenizer.encode_plus(sequence_0,\n",
    "                                                sequence_1,\n",
    "                                                max_length=1024,\n",
    "                                                padding='max_length',\n",
    "                                                truncation=True,\n",
    "                                                return_tensors='pt')\n",
    "\n",
    "example_inputs = tokenized_sequence_pair['input_ids'], tokenized_sequence_pair['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's compile the model from scatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModel.from_pretrained('BAAI/bge-m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = torch.neuron.trace(base_model, example_inputs, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = compiled_model(*example_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴파일이 완료된 모델을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model.save('compiled_model/model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장된 모델이 잘 동작하는지 `torch.jit.load`로 다시 테스트합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/ubuntu/yanolja/compiled_model/model.pt\"\n",
    "model_neuron = torch.jit.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_hidden_state': tensor([[[-1.1719,  0.4141, -1.1562,  ...,  0.5625, -0.8984,  1.5391],\n",
       "          [-0.1982, -0.4531, -0.6367,  ...,  1.3672, -0.5547,  1.6875],\n",
       "          [-0.3027, -0.0093, -0.6602,  ...,  1.1484, -0.2051,  1.8594],\n",
       "          ...,\n",
       "          [-0.7305,  0.4590, -0.5352,  ...,  0.9219, -0.6914,  1.3750],\n",
       "          [-0.7305,  0.4590, -0.5352,  ...,  0.9219, -0.6914,  1.3750],\n",
       "          [-0.7305,  0.4590, -0.5352,  ...,  0.9219, -0.6914,  1.3750]]]),\n",
       " 'pooler_output': tensor([[-0.9062, -0.0457,  0.3613,  ..., -0.4355,  0.2236, -0.2256]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model_neuron(*example_inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Similaritiy of two sentences are 0.838'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "sentences = [\"I'm happy\", \"I'm full of joy\"]\n",
    "\n",
    "tokenized_1 = tokenizer.encode_plus(sentences[0],max_length=1024,padding='max_length',truncation=True,return_tensors='pt')\n",
    "tokenized_2 = tokenizer.encode_plus(sentences[1],max_length=1024,padding='max_length',truncation=True,return_tensors='pt')\n",
    "\n",
    "inputs_1 = tokenized_1['input_ids'], tokenized_1['attention_mask']\n",
    "inputs_2 = tokenized_2['input_ids'], tokenized_2['attention_mask']\n",
    "\n",
    "embedding_1 = model_neuron(*inputs_1)\n",
    "embedding_2 = model_neuron(*inputs_2)\n",
    "\n",
    "sim = util.pytorch_cos_sim(embedding_1['pooler_output'], embedding_2['pooler_output'])\n",
    "\n",
    "out_str = f'Similaritiy of two sentences are {round(sim[0][0].item(),3)}'\n",
    "out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8381])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cosine_similarity(embedding_1['pooler_output'], embedding_2['pooler_output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "준비된 모델 파일과 `inference.py`를 tar.gz로 압축해서 업로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy inference.py and requirements.txt to neuron_model/code\n",
    "!cd compiled_model && tar -czvf ../model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/ubuntu/yanolja\n",
    "!aws s3 cp model.tar.gz s3://sagemaker-ap-northeast-2-236241703319/neuron-experiments/bge-m3/compiled-model/compiled_model.tar.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yanolja",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
