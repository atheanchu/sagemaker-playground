{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62c3b8fe-18d8-41ee-af85-4c8fd196135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U -q sagemaker\n",
    "!pip install -U -q transformer\n",
    "!pip install torch==1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8173984e-55cc-4fe6-ae37-74d297434e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu102\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import transformers\n",
    "import sagemaker\n",
    "import boto3\n",
    "import torch\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sess_bucket = sagemaker_session.default_bucket()\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d578f53-4333-470e-a515-6d806706ee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "model = transformers.AutoModel.from_pretrained(\n",
    "    \"BAAI/bge-m3\", return_dict=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3335df5e-8abb-4605-bbdb-69035c7148d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "inputs = \"Hello, SageMaker\"\n",
    "encoded_input = tokenizer(inputs, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded_input)\n",
    "print(str(outputs[1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee639d-fe8a-4c20-beb6-c9913fb64553",
   "metadata": {},
   "source": [
    "# Test Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7261773d-91d1-411a-88f4-daeebddeb857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "[\"Welcome to AWS Summit San Francisco 2022! Thank you for attending the workshop on using Huggingface transformers on Inferentia instances.\", \"Welcome to AWS Summit San Francisco 2022! Thank you for attending the workshop on using Huggingface transformers on Inferentia instances.\"]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "seq_0 = \"Welcome to AWS Summit San Francisco 2022! Thank you for attending the workshop on using Huggingface transformers on Inferentia instances.\"\n",
    "seq_1 = seq_0\n",
    "payload = (seq_0, seq_1)\n",
    "\n",
    "serializer = JSONSerializer()\n",
    "serialized_input_data = serializer.serialize(payload)\n",
    "print(serialized_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd493b60-313c-43cf-9061-1a0aea3a1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "\n",
    "# Set up the SageMaker runtime client\n",
    "runtime = boto3.client('runtime.sagemaker')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b38a043-d2c6-4c20-bb43-36c16795b485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"(tensor([[[-0.2425,  0.1145, -0.7044,  ...,  0.9198, -0.1090,  1.0912],\\\\n         [ 0.0309, -0.6001, -0.5553,  ...,  1.6043, -0.5135,  1.2376],\\\\n         [-0.0437, -0.6375, -0.4062,  ...,  1.2313, -0.6825,  0.7152],\\\\n         ...,\\\\n         [ 0.1653,  0.6219, -0.5957,  ...,  1.2212,  0.0403,  0.9938],\\\\n         [ 0.1653,  0.6219, -0.5957,  ...,  1.2212,  0.0403,  0.9938],\\\\n         [ 0.1653,  0.6219, -0.5957,  ...,  1.2212,  0.0403,  0.9938]]]), tensor([[0.1304, 0.0103, 0.0873,  ..., 0.4091, 0.5241, 0.0126]]))\"', 'application/json']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the endpoint name\n",
    "endpoint_name = 'bge-m3-inf1-202405-2805-4315'\n",
    "\n",
    "# Make a prediction request to the endpoint\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=serialized_input_data\n",
    ")\n",
    "\n",
    "# Deserialize the response\n",
    "deserializer = JSONDeserializer()\n",
    "response_body = BytesIO(response['Body'].read())\n",
    "result = deserializer.deserialize(response_body, 'application/json')\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaa55134-17dd-4e81-a45d-84369b5b0a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         ...,\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan],\n",
      "         [nan, nan, nan,  ..., nan, nan, nan]]]), tensor([[nan, nan, nan,  ..., nan, nan, nan]]))\n"
     ]
    }
   ],
   "source": [
    "# Define the endpoint name\n",
    "endpoint_name = 'bge-m3-inf1-202405-2611-5529'\n",
    "\n",
    "# Make a prediction request to the endpoint\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=serialized_input_data\n",
    ")\n",
    "\n",
    "# Deserialize the response\n",
    "deserializer = JSONDeserializer()\n",
    "response_body = BytesIO(response['Body'].read())\n",
    "result = deserializer.deserialize(response_body, 'application/json')\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e3133-5703-46a0-b9ae-ebd6fe64fa59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
